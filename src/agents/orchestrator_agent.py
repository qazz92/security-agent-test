"""
ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸
CrewAI ê¸°ë°˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ë³´ì•ˆ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì¡°ìœ¨
"""

import asyncio
import time
import json
import logging
import os
from typing import Dict, List, Any, Optional
from datetime import datetime

from .security_crew import SecurityCrewManager
from ..models.llm_config import create_security_llm, SecurityModelSelector

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


class SecurityOrchestrator:
    """CrewAI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ ë° ìˆ˜ì • ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    def __init__(self, verbose: bool = True):
        """
        Args:
            verbose: ìƒì„¸ ë¡œê¹… í™œì„±í™”
        """
        self.verbose = verbose

        # CrewAI ë°©ì‹: ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ìë™ í˜‘ì—…
        logger.info("ğŸ¤– Using CrewAI for multi-agent orchestration")
        self.crew_manager = SecurityCrewManager(verbose=verbose)

        # ì „ì²´ ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ì €ì¥
        self.workflow_results = {}
        self.performance_metrics = {
            "workflow_start_time": None,
            "workflow_end_time": None,
            "total_duration": None,
            "phases_completed": [],
            "agents_used": [],
            "orchestration_mode": "crewai"
        }

    async def analyze_and_remediate(
        self,
        project_path: str,
        user_query: str = "Comprehensive security analysis and remediation"
    ) -> Dict[str, Any]:
        """CrewAI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ ë° ìˆ˜ì • ë°©ì•ˆ ìƒì„± ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""

        self.performance_metrics["workflow_start_time"] = time.time()

        try:
            logger.info("ğŸ¤– Starting CrewAI-based security analysis...")

            # CrewAI Crew ì‹¤í–‰ (ë¹„ë™ê¸° ë˜í¼)
            loop = asyncio.get_event_loop()
            github_repo_url = os.environ.get('GITHUB_REPO_URL', 'https://github.com/qazz92/security-agent-test')

            crew_result = await loop.run_in_executor(
                None,
                lambda: self.crew_manager.analyze_project(project_path, github_repo_url)
            )

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.performance_metrics["workflow_end_time"] = time.time()
            self.performance_metrics["total_duration"] = (
                self.performance_metrics["workflow_end_time"] -
                self.performance_metrics["workflow_start_time"]
            )
            self.performance_metrics["agents_used"] = crew_result.get("agents_used", [])
            self.performance_metrics["phases_completed"] = ["crewai_analysis"]

            # CrewAI ê²°ê³¼ êµ¬ì¡°í™”
            workflow_results = {
                "workflow_metadata": {
                    "project_path": project_path,
                    "user_query": user_query,
                    "analysis_timestamp": datetime.now().isoformat(),
                    "workflow_version": "2.0-crewai",
                    "orchestration_mode": "crewai",
                    "agents_used": crew_result.get("agents_used", [])
                },
                "crewai_result": crew_result.get("result", ""),
                "success": crew_result.get("success", False),
                "performance_metrics": self.performance_metrics,
                "github_repo_url": github_repo_url
            }

            self.workflow_results = workflow_results

            logger.info("âœ… CrewAI analysis completed successfully")
            logger.info(f"â±ï¸ Total duration: {self.performance_metrics['total_duration']:.1f}s")

            return workflow_results

        except Exception as e:
            logger.error(f"âŒ CrewAI analysis failed: {e}")
            return self._create_error_result(
                f"CrewAI workflow execution failed: {str(e)}",
                project_path
            )

    def _create_error_result(self, error_message: str, project_path: str, *args) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return {
            "error": error_message,
            "project_path": project_path,
            "timestamp": datetime.now().isoformat(),
            "success": False
        }

    def get_workflow_summary(self) -> str:
        """ì›Œí¬í”Œë¡œìš° ìš”ì•½ ìƒì„±"""

        if not self.workflow_results:
            return "No workflow results available."

        performance = self.performance_metrics
        metadata = self.workflow_results.get("workflow_metadata", {})

        return f"""
ğŸ¯ CrewAI Workflow Summary:
  - Total Duration: {performance.get('total_duration', 0):.1f} seconds
  - Orchestration Mode: {metadata.get('orchestration_mode', 'crewai')}
  - Agents Used: {', '.join(performance.get('agents_used', []))}
  - Success: {'âœ…' if self.workflow_results.get('success') else 'âŒ'}

âœ… Ready for review!
"""

    def save_results(self, output_file: str = None) -> str:
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""

        if not self.workflow_results:
            return "No results to save."

        output_file = output_file or f"security_analysis_{int(time.time())}.json"

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.workflow_results, f, indent=2, ensure_ascii=False, default=str)

            return f"Results saved to {output_file}"

        except Exception as e:
            return f"Failed to save results: {str(e)}"