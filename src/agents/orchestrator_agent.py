"""
ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—ì´ì „íŠ¸
ë³´ì•ˆ ë¶„ì„ê³¼ ìˆ˜ì • ë°©ì•ˆ ì—ì´ì „íŠ¸ë“¤ì„ ì¡°ìœ¨í•˜ëŠ” ë©”ì¸ ì—ì´ì „íŠ¸
"""

import asyncio
import time
import json
from typing import Dict, List, Any, Optional
from datetime import datetime

from .security_agent import SecurityAnalysisAgent
from .remediation_agent import RemediationAgent
from ..models.llm_config import create_security_llm, SecurityModelSelector


class SecurityOrchestrator:
    """ë³´ì•ˆ ë¶„ì„ ë° ìˆ˜ì • ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ëŠ” ì¢…í•©ì ì¸ ë¶„ì„ê³¼ ì˜ì‚¬ê²°ì •ì„ ë‹´ë‹¹
        self.llm = create_security_llm(
            task_type="comprehensive_analysis",
            security_level="HIGH"
        )

        # ì „ë¬¸ ì—ì´ì „íŠ¸ë“¤ ì´ˆê¸°í™”
        self.security_agent = SecurityAnalysisAgent(verbose=verbose)
        self.remediation_agent = RemediationAgent(verbose=verbose)

        # ì „ì²´ ì›Œí¬í”Œë¡œìš° ê²°ê³¼ ì €ì¥
        self.workflow_results = {}
        self.performance_metrics = {
            "workflow_start_time": None,
            "workflow_end_time": None,
            "total_duration": None,
            "phases_completed": [],
            "agents_used": []
        }

    async def analyze_and_remediate(
        self,
        project_path: str,
        user_query: str = "Comprehensive security analysis and remediation"
    ) -> Dict[str, Any]:
        """ì „ì²´ ë³´ì•ˆ ë¶„ì„ ë° ìˆ˜ì • ë°©ì•ˆ ìƒì„± ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""

        self.performance_metrics["workflow_start_time"] = time.time()

        try:
            if self.verbose:
                print("\n" + "="*70)
                print("ğŸš€ STARTING COMPREHENSIVE SECURITY WORKFLOW")
                print("="*70)
                print(f"ğŸ“ Project: {project_path}")
                print(f"ğŸ“ Query: {user_query}")
                print(f"â° Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                print("="*70 + "\n")

            # Phase 1: ë³´ì•ˆ ë¶„ì„
            print("\n" + "="*70)
            print("ğŸ” PHASE 1: SECURITY ANALYSIS")
            print("="*70)
            print("ğŸ“‹ Step 1/3: Analyzing project for security vulnerabilities...")
            print("   â†’ This may take 30-60 seconds depending on project size")

            phase1_start = time.time()
            security_analysis = await self.security_agent.analyze_project(project_path, user_query)
            phase1_duration = time.time() - phase1_start
            self.performance_metrics["phases_completed"].append("security_analysis")
            self.performance_metrics["agents_used"].append("security_agent")

            if "error" in security_analysis:
                return self._create_error_result(
                    f"Security analysis failed: {security_analysis['error']}",
                    project_path
                )

            # ë³´ì•ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print(f"\nâœ… Phase 1 completed in {phase1_duration:.1f}s")
            if self.verbose:
                print(self.security_agent.get_analysis_summary())

            # Phase 2: ìˆ˜ì • ë°©ì•ˆ ìƒì„±
            print("\n" + "="*70)
            print("ğŸ”§ PHASE 2: REMEDIATION PLANNING")
            print("="*70)
            print("ğŸ“‹ Step 2/3: Generating remediation plans and fix codes...")
            print("   â†’ Creating PR templates and documentation")

            phase2_start = time.time()
            project_info = security_analysis.get("detailed_results", {}).get("project_info", {})
            remediation_plan = await self.remediation_agent.generate_remediation_plan(
                security_analysis, project_info
            )
            phase2_duration = time.time() - phase2_start
            self.performance_metrics["phases_completed"].append("remediation_planning")
            self.performance_metrics["agents_used"].append("remediation_agent")

            if "error" in remediation_plan:
                return self._create_error_result(
                    f"Remediation planning failed: {remediation_plan['error']}",
                    project_path,
                    security_analysis
                )

            # ìˆ˜ì • ë°©ì•ˆ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print(f"\nâœ… Phase 2 completed in {phase2_duration:.1f}s")
            if self.verbose:
                print(self.remediation_agent.get_remediation_summary())

            # Phase 3: ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
            print("\n" + "="*70)
            print("ğŸ“Š PHASE 3: FINAL REPORT GENERATION")
            print("="*70)
            print("ğŸ“‹ Step 3/3: Generating comprehensive security report...")
            print("   â†’ Calculating risk scores and ROI analysis")

            phase3_start = time.time()
            final_report = await self._generate_final_report(
                security_analysis, remediation_plan, project_path, user_query
            )
            phase3_duration = time.time() - phase3_start
            self.performance_metrics["phases_completed"].append("final_report")

            # ì›Œí¬í”Œë¡œìš° ì™„ë£Œ
            self.performance_metrics["workflow_end_time"] = time.time()
            self.performance_metrics["total_duration"] = (
                self.performance_metrics["workflow_end_time"] -
                self.performance_metrics["workflow_start_time"]
            )

            # ì „ì²´ ê²°ê³¼ êµ¬ì„±
            workflow_results = {
                "workflow_metadata": {
                    "project_path": project_path,
                    "user_query": user_query,
                    "analysis_timestamp": datetime.now().isoformat(),
                    "workflow_version": "1.0",
                    "agents_used": list(set(self.performance_metrics["agents_used"]))
                },
                "security_analysis": security_analysis,
                "remediation_plan": remediation_plan,
                "final_report": final_report,
                "performance_metrics": self.performance_metrics,
                "executive_summary": self._create_executive_summary(security_analysis, remediation_plan)
            }

            self.workflow_results = workflow_results

            # ìµœì¢… ì™„ë£Œ ë©”ì‹œì§€
            print(f"\nâœ… Phase 3 completed in {phase3_duration:.1f}s")
            print("\n" + "="*70)
            print("âœ… WORKFLOW COMPLETED SUCCESSFULLY")
            print("="*70)
            print(f"â° Total Duration: {self.performance_metrics['total_duration']:.1f}s")
            print(f"ğŸ“Š Phase Breakdown:")
            print(f"   â€¢ Phase 1 (Security Analysis): {phase1_duration:.1f}s")
            print(f"   â€¢ Phase 2 (Remediation Planning): {phase2_duration:.1f}s")
            print(f"   â€¢ Phase 3 (Final Report): {phase3_duration:.1f}s")
            print("="*70)

            if self.verbose:
                print(self._get_workflow_summary())

            return workflow_results

        except Exception as e:
            self.performance_metrics["workflow_end_time"] = time.time()
            return self._create_error_result(
                f"Workflow execution failed: {str(e)}",
                project_path
            )

    async def _generate_final_report(
        self,
        security_analysis: Dict[str, Any],
        remediation_plan: Dict[str, Any],
        project_path: str,
        user_query: str
    ) -> Dict[str, Any]:
        """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""

        try:
            # ë³´ì•ˆ ì ìˆ˜ ê³„ì‚°
            vulnerabilities = security_analysis.get("vulnerabilities", [])
            severity_counts = security_analysis.get("analysis_summary", {}).get("severity_distribution", {})

            security_score = self._calculate_security_score(severity_counts)
            risk_level = self._determine_risk_level(severity_counts)

            # ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ í‰ê°€
            business_impact = self._assess_business_impact(vulnerabilities, severity_counts)

            # ì»´í”Œë¼ì´ì–¸ìŠ¤ ìƒíƒœ
            compliance_status = self._evaluate_compliance_status(vulnerabilities)

            # ROI ë¶„ì„
            roi_analysis = self._calculate_security_roi(
                vulnerabilities,
                remediation_plan.get("estimated_effort", {})
            )

            return {
                "report_metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "project_path": project_path,
                    "report_version": "1.0"
                },
                "security_posture": {
                    "overall_score": security_score,
                    "risk_level": risk_level,
                    "vulnerabilities_summary": {
                        "total": len(vulnerabilities),
                        "by_severity": severity_counts,
                        "immediate_action_required": severity_counts.get("CRITICAL", 0) > 0
                    }
                },
                "business_impact": business_impact,
                "compliance_status": compliance_status,
                "remediation_overview": {
                    "total_effort": remediation_plan.get("estimated_effort", {}),
                    "implementation_phases": len(remediation_plan.get("implementation_plan", {})),
                    "estimated_completion": self._estimate_completion_timeline(remediation_plan)
                },
                "roi_analysis": roi_analysis,
                "recommendations": self._generate_strategic_recommendations(
                    security_analysis, remediation_plan
                ),
                "next_steps": self._define_next_steps(security_analysis, remediation_plan)
            }

        except Exception as e:
            return {
                "error": f"Final report generation failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    def _calculate_security_score(self, severity_counts: Dict[str, int]) -> int:
        """ë³´ì•ˆ ì ìˆ˜ ê³„ì‚° (100ì  ë§Œì )"""
        total_vulns = sum(severity_counts.values())
        if total_vulns == 0:
            return 100

        # ì‹¬ê°ë„ë³„ ê°€ì¤‘ì¹˜
        weighted_score = (
            severity_counts.get("CRITICAL", 0) * 25 +
            severity_counts.get("HIGH", 0) * 15 +
            severity_counts.get("MEDIUM", 0) * 8 +
            severity_counts.get("LOW", 0) * 3
        )

        return max(0, 100 - weighted_score)

    def _determine_risk_level(self, severity_counts: Dict[str, int]) -> str:
        """ìœ„í—˜ ìˆ˜ì¤€ ê²°ì •"""
        if severity_counts.get("CRITICAL", 0) > 0:
            return "CRITICAL"
        elif severity_counts.get("HIGH", 0) > 2:
            return "HIGH"
        elif severity_counts.get("HIGH", 0) > 0 or severity_counts.get("MEDIUM", 0) > 5:
            return "MEDIUM"
        else:
            return "LOW"

    def _assess_business_impact(self, vulnerabilities: List[Dict], severity_counts: Dict[str, int]) -> Dict[str, Any]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ í‰ê°€"""

        # ì ì¬ì  í”¼í•´ ì‹œë‚˜ë¦¬ì˜¤
        impact_scenarios = []

        if severity_counts.get("CRITICAL", 0) > 0:
            impact_scenarios.extend([
                "ë°ì´í„° ìœ ì¶œë¡œ ì¸í•œ ê³ ê° ì‹ ë¢°ë„ í•˜ë½",
                "ê·œì œ ìœ„ë°˜ ì‹œ ë²•ì  ì œì¬ ë° ë²Œê¸ˆ",
                "ì‹œìŠ¤í…œ ì¹¨í•´ë¡œ ì¸í•œ ì„œë¹„ìŠ¤ ì¤‘ë‹¨"
            ])

        if any(v.get("type") == "SQL_INJECTION" for v in vulnerabilities):
            impact_scenarios.append("ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ë…¸ì¶œ ìœ„í—˜")

        if any("SECRET" in v.get("type", "") for v in vulnerabilities):
            impact_scenarios.append("API í‚¤ ë° ìê²©ì¦ëª… ë…¸ì¶œ")

        # ë¹„ìš© ì¶”ì •
        estimated_breach_cost = self._estimate_breach_cost(severity_counts)

        return {
            "risk_scenarios": impact_scenarios,
            "estimated_breach_cost": estimated_breach_cost,
            "compliance_risk": "HIGH" if severity_counts.get("CRITICAL", 0) > 0 else "MEDIUM",
            "reputation_impact": "SEVERE" if severity_counts.get("CRITICAL", 0) > 2 else "MODERATE",
            "operational_impact": {
                "immediate": severity_counts.get("CRITICAL", 0),
                "short_term": severity_counts.get("HIGH", 0),
                "long_term": severity_counts.get("MEDIUM", 0) + severity_counts.get("LOW", 0)
            }
        }

    def _estimate_breach_cost(self, severity_counts: Dict[str, int]) -> Dict[str, Any]:
        """ë°ì´í„° ì¹¨í•´ ë¹„ìš© ì¶”ì •"""

        # ì—…ê³„ í‰ê·  ë¹„ìš© ê¸°ì¤€ (USD)
        base_cost_per_record = 150  # ê°œì¸ì •ë³´ 1ê±´ë‹¹ í‰ê·  ë¹„ìš©
        estimated_records_at_risk = 1000  # ê¸°ë³¸ ì¶”ì •ê°’

        # ì‹¬ê°ë„ë³„ ë¹„ìš© ìŠ¹ìˆ˜
        cost_multiplier = 1.0
        if severity_counts.get("CRITICAL", 0) > 0:
            cost_multiplier = 3.0
        elif severity_counts.get("HIGH", 0) > 0:
            cost_multiplier = 2.0

        estimated_cost = base_cost_per_record * estimated_records_at_risk * cost_multiplier

        return {
            "estimated_total_cost": estimated_cost,
            "cost_breakdown": {
                "data_recovery": estimated_cost * 0.3,
                "legal_compliance": estimated_cost * 0.2,
                "reputation_damage": estimated_cost * 0.3,
                "operational_disruption": estimated_cost * 0.2
            },
            "currency": "USD",
            "confidence_level": "MEDIUM"
        }

    def _evaluate_compliance_status(self, vulnerabilities: List[Dict]) -> Dict[str, Any]:
        """ì»´í”Œë¼ì´ì–¸ìŠ¤ ìƒíƒœ í‰ê°€"""

        # ì£¼ìš” ì»´í”Œë¼ì´ì–¸ìŠ¤ í”„ë ˆì„ì›Œí¬ ì²´í¬
        frameworks = {
            "GDPR": {"compliant": True, "violations": []},
            "PCI_DSS": {"compliant": True, "violations": []},
            "SOX": {"compliant": True, "violations": []},
            "HIPAA": {"compliant": True, "violations": []}
        }

        # ì·¨ì•½ì ë³„ ì»´í”Œë¼ì´ì–¸ìŠ¤ ì˜í–¥ í‰ê°€
        for vuln in vulnerabilities:
            vuln_type = vuln.get("type", "")

            if "SQL_INJECTION" in vuln_type:
                frameworks["PCI_DSS"]["compliant"] = False
                frameworks["PCI_DSS"]["violations"].append("Data protection requirements")
                frameworks["GDPR"]["violations"].append("Data security measures")

            if "SECRET" in vuln_type:
                for framework in frameworks.values():
                    framework["compliant"] = False
                    framework["violations"].append("Access control requirements")

        return {
            "frameworks": frameworks,
            "overall_compliance": all(f["compliant"] for f in frameworks.values()),
            "critical_violations": sum(len(f["violations"]) for f in frameworks.values()),
            "remediation_required": not all(f["compliant"] for f in frameworks.values())
        }

    def _calculate_security_roi(self, vulnerabilities: List[Dict], effort: Dict[str, Any]) -> Dict[str, Any]:
        """ë³´ì•ˆ íˆ¬ì ìˆ˜ìµë¥  ê³„ì‚°"""

        # ìˆ˜ì • ë¹„ìš© ì¶”ì • (ê°œë°œì ì‹œê¸‰ ê¸°ì¤€)
        hourly_rate = 100  # USD per hour
        total_hours = effort.get("total_hours", 0)
        remediation_cost = total_hours * hourly_rate

        # ì ì¬ì  ì¹¨í•´ ë¹„ìš© (ìœ„ì—ì„œ ê³„ì‚°)
        potential_breach_cost = 150000  # ê¸°ë³¸ ì¶”ì •ê°’

        # ROI ê³„ì‚°
        cost_avoidance = potential_breach_cost
        roi_percentage = ((cost_avoidance - remediation_cost) / remediation_cost * 100) if remediation_cost > 0 else 0

        return {
            "remediation_cost": remediation_cost,
            "potential_breach_cost": potential_breach_cost,
            "cost_avoidance": cost_avoidance,
            "roi_percentage": round(roi_percentage, 1),
            "payback_period": "Immediate" if roi_percentage > 0 else "Long-term",
            "recommendation": "PROCEED" if roi_percentage > 100 else "EVALUATE"
        }

    def _generate_strategic_recommendations(
        self,
        security_analysis: Dict[str, Any],
        remediation_plan: Dict[str, Any]
    ) -> List[str]:
        """ì „ëµì  ê¶Œì¥ì‚¬í•­ ìƒì„±"""

        recommendations = []
        severity_counts = security_analysis.get("analysis_summary", {}).get("severity_distribution", {})

        # ì¦‰ì‹œ ì¡°ì¹˜ ê¶Œì¥ì‚¬í•­
        if severity_counts.get("CRITICAL", 0) > 0:
            recommendations.append("ğŸš¨ Critical ì·¨ì•½ì  ì¦‰ì‹œ ìˆ˜ì • - ìš´ì˜ ì¤‘ë‹¨ ìœ„í—˜")

        # í”„ë¡œì„¸ìŠ¤ ê°œì„  ê¶Œì¥ì‚¬í•­
        if sum(severity_counts.values()) > 10:
            recommendations.extend([
                "ğŸ”„ ì •ê¸°ì ì¸ ë³´ì•ˆ ìŠ¤ìº” í”„ë¡œì„¸ìŠ¤ êµ¬ì¶•",
                "ğŸ‘¥ ê°œë°œíŒ€ ë³´ì•ˆ êµìœ¡ ì‹¤ì‹œ",
                "ğŸ›¡ï¸ DevSecOps íŒŒì´í”„ë¼ì¸ ë„ì…"
            ])

        # ê¸°ìˆ ì  ê¶Œì¥ì‚¬í•­
        vuln_types = set()
        for vuln in security_analysis.get("vulnerabilities", []):
            vuln_types.add(vuln.get("type", ""))

        if "SQL_INJECTION" in vuln_types:
            recommendations.append("ğŸ—ƒï¸ ORM ì‚¬ìš©ìœ¼ë¡œ SQL Injection ê·¼ë³¸ ì°¨ë‹¨")

        if "SECRET" in " ".join(vuln_types):
            recommendations.append("ğŸ” Secret Management ì†”ë£¨ì…˜ ë„ì…")

        # ê±°ë²„ë„ŒìŠ¤ ê¶Œì¥ì‚¬í•­
        recommendations.extend([
            "ğŸ“‹ ë³´ì•ˆ ì½”ë”© ê°€ì´ë“œë¼ì¸ ìˆ˜ë¦½",
            "ğŸ” ì½”ë“œ ë¦¬ë·°ì— ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸ í¬í•¨",
            "ğŸ“Š ë³´ì•ˆ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•"
        ])

        return recommendations

    def _define_next_steps(
        self,
        security_analysis: Dict[str, Any],
        remediation_plan: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ë‹¤ìŒ ë‹¨ê³„ ì •ì˜"""

        steps = []
        severity_counts = security_analysis.get("analysis_summary", {}).get("severity_distribution", {})

        # 1. ì¦‰ì‹œ ì¡°ì¹˜ ë‹¨ê³„
        if severity_counts.get("CRITICAL", 0) > 0:
            steps.append({
                "phase": "immediate",
                "timeline": "24 hours",
                "actions": [
                    "Critical ì·¨ì•½ì  ìˆ˜ì • ì‘ì—… ì‹œì‘",
                    "ì„ì‹œ ë³´ì•ˆ ì¡°ì¹˜ ì ìš©",
                    "ëª¨ë‹ˆí„°ë§ ê°•í™”"
                ],
                "responsible": "Development Team Lead",
                "priority": "P0"
            })

        # 2. ë‹¨ê¸° ì¡°ì¹˜ ë‹¨ê³„
        steps.append({
            "phase": "short_term",
            "timeline": "1-2 weeks",
            "actions": [
                "High severity ì·¨ì•½ì  ìˆ˜ì •",
                "ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±",
                "ì½”ë“œ ë¦¬ë·° ë° ë°°í¬"
            ],
            "responsible": "Development Team",
            "priority": "P1"
        })

        # 3. ì¤‘ì¥ê¸° ê°œì„  ë‹¨ê³„
        steps.append({
            "phase": "medium_term",
            "timeline": "1-3 months",
            "actions": [
                "Medium/Low ì·¨ì•½ì  ìˆ˜ì •",
                "ë³´ì•ˆ í”„ë¡œì„¸ìŠ¤ ê°œì„ ",
                "íŒ€ êµìœ¡ ì‹¤ì‹œ"
            ],
            "responsible": "Security Team",
            "priority": "P2"
        })

        # 4. ì§€ì†ì  ê°œì„  ë‹¨ê³„
        steps.append({
            "phase": "continuous",
            "timeline": "Ongoing",
            "actions": [
                "ì •ê¸° ë³´ì•ˆ ìŠ¤ìº” ìë™í™”",
                "ë³´ì•ˆ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§",
                "í”„ë¡œì„¸ìŠ¤ ê°œì„ "
            ],
            "responsible": "DevSecOps Team",
            "priority": "P3"
        })

        return steps

    def _estimate_completion_timeline(self, remediation_plan: Dict[str, Any]) -> str:
        """ì™„ë£Œ ì˜ˆìƒ ì‹œì  ê³„ì‚°"""

        effort = remediation_plan.get("estimated_effort", {})
        total_days = effort.get("total_days", 0)

        if total_days <= 1:
            return "1 day"
        elif total_days <= 7:
            return f"{int(total_days)} days"
        elif total_days <= 30:
            return f"{int(total_days / 7)} weeks"
        else:
            return f"{int(total_days / 30)} months"

    def _create_executive_summary(
        self,
        security_analysis: Dict[str, Any],
        remediation_plan: Dict[str, Any]
    ) -> str:
        """ê²½ì˜ì§„ì„ ìœ„í•œ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""

        severity_counts = security_analysis.get("analysis_summary", {}).get("severity_distribution", {})
        total_vulns = sum(severity_counts.values())
        effort = remediation_plan.get("estimated_effort", {})

        summary = f"""
# Executive Security Summary

## ğŸ¯ Key Findings
- **Total Security Issues**: {total_vulns}
- **Critical Issues**: {severity_counts.get('CRITICAL', 0)} (require immediate attention)
- **High Priority Issues**: {severity_counts.get('HIGH', 0)}
- **Overall Risk Level**: {self._determine_risk_level(severity_counts)}

## ğŸ’¼ Business Impact
- **Immediate Action Required**: {'YES' if severity_counts.get('CRITICAL', 0) > 0 else 'NO'}
- **Estimated Remediation Time**: {effort.get('total_days', 0)} days
- **Recommended Team Size**: {effort.get('team_size_recommendation', 1)} developers

## ğŸš€ Recommended Actions
1. **Immediate** (24-48 hours): Fix {severity_counts.get('CRITICAL', 0)} critical issues
2. **Short-term** (1-2 weeks): Address {severity_counts.get('HIGH', 0)} high-priority issues
3. **Medium-term** (1-3 months): Implement security process improvements

## ğŸ“Š Success Metrics
- Zero critical vulnerabilities within 48 hours
- 90%+ reduction in high-risk issues within 2 weeks
- Automated security scanning in place within 1 month

**Next Step**: Approve immediate resource allocation for critical issue remediation.
"""

        return summary.strip()

    def _create_error_result(
        self,
        error_message: str,
        project_path: str,
        partial_results: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """ì—ëŸ¬ ë°œìƒ ì‹œ ê²°ê³¼ ìƒì„±"""

        return {
            "error": error_message,
            "project_path": project_path,
            "timestamp": datetime.now().isoformat(),
            "partial_results": partial_results or {},
            "performance_metrics": self.performance_metrics,
            "recovery_suggestions": [
                "Check project path accessibility",
                "Verify tool dependencies (Trivy, etc.)",
                "Check API key configuration",
                "Review error logs for specific issues"
            ]
        }

    def _get_workflow_summary(self) -> str:
        """ì›Œí¬í”Œë¡œìš° ìš”ì•½ ìƒì„±"""

        if not self.workflow_results:
            return "No workflow results available."

        security_summary = self.workflow_results.get("security_analysis", {}).get("analysis_summary", {})
        remediation_summary = self.workflow_results.get("remediation_plan", {}).get("remediation_summary", {})
        performance = self.performance_metrics

        return f"""
ğŸ¯ Workflow Summary:
  - Total Duration: {performance.get('total_duration', 0):.1f} seconds
  - Phases Completed: {len(performance.get('phases_completed', []))}
  - Agents Used: {len(set(performance.get('agents_used', [])))}

ğŸ” Security Analysis:
  - Vulnerabilities Found: {security_summary.get('total_vulnerabilities', 0)}
  - Critical Issues: {security_summary.get('severity_distribution', {}).get('CRITICAL', 0)}
  - Analysis Tools Used: {len(security_summary.get('tools_used', []))}

ğŸ”§ Remediation Plan:
  - Fix Codes Generated: {remediation_summary.get('fixes_generated', 0)}
  - PR Template: {'âœ…' if remediation_summary.get('pr_template_created') else 'âŒ'}
  - Documentation: {'âœ…' if remediation_summary.get('documentation_created') else 'âŒ'}

âœ… Ready for implementation!
"""

    def save_results(self, output_file: str = None) -> str:
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""

        if not self.workflow_results:
            return "No results to save."

        output_file = output_file or f"security_analysis_{int(time.time())}.json"

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.workflow_results, f, indent=2, ensure_ascii=False, default=str)

            return f"Results saved to {output_file}"

        except Exception as e:
            return f"Failed to save results: {str(e)}"