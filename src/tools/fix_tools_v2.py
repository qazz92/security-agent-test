"""
LLM ê¸°ë°˜ ë³´ì•ˆ ì½”ë“œ ìˆ˜ì • íˆ´ (V2)
Templateì„ ê°€ì´ë“œë¡œë§Œ ì‚¬ìš©í•˜ê³  LLMì´ ì‹¤ì œ ì½”ë“œë¥¼ ë¶„ì„/ìˆ˜ì •

V2 ê°œì„ ì‚¬í•­:
- LLM ê¸°ë°˜ ì‹¤ì œ ì½”ë“œ ë¶„ì„ ë° ìˆ˜ì • (ë³€ìˆ˜ëª…/ë¡œì§ ë³´ì¡´)
- Templateì€ "ë³´ì•ˆ ì›ì¹™ ê°€ì´ë“œ"ë¡œë§Œ ì‚¬ìš©
- Structured Outputìœ¼ë¡œ ì¼ê´€ì„± ë³´ì¥
- ëª…í™•í•œ ì…ë ¥ í˜•ì‹ ìš”êµ¬ (Agent í”„ë¡¬í”„íŠ¸ì—ì„œ í˜•ì‹ ì§€ì •)
"""

import time
import json
import os
import logging
from typing import Dict, List, Any, Optional
from langchain_core.tools import BaseTool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# ============================================================================
# Security Patterns (Templateì„ "ê°€ì´ë“œë¼ì¸"ìœ¼ë¡œ ì¬ì •ì˜)
# ============================================================================

SECURITY_PATTERNS = {
    "SQL_INJECTION": {
        "name": "SQL Injection",
        "description": "ì‚¬ìš©ì ì…ë ¥ì´ SQL ì¿¼ë¦¬ì— ì§ì ‘ ì‚½ì…ë˜ì–´ ì„ì˜ì˜ SQL ëª…ë ¹ ì‹¤í–‰ ê°€ëŠ¥",
        "principle": "Parameterized queries (prepared statements)ë¥¼ ì‚¬ìš©í•˜ì—¬ SQLê³¼ ë°ì´í„°ë¥¼ ë¶„ë¦¬",
        "vulnerable_patterns": [
            "f-stringìœ¼ë¡œ SQL ì¿¼ë¦¬ êµ¬ì„±: f\"SELECT * FROM table WHERE id = {user_input}\"",
            ".format()ìœ¼ë¡œ SQL ì¿¼ë¦¬ êµ¬ì„±: \"SELECT * FROM {} WHERE id = {}\".format(table, id)",
            "ë¬¸ìì—´ ì—°ê²°ë¡œ SQL ì¿¼ë¦¬ êµ¬ì„±: \"SELECT * FROM \" + table_name"
        ],
        "secure_patterns": [
            "Parameterized query: cursor.execute(\"SELECT * FROM table WHERE id = ?\", (user_input,))",
            "ORM ì‚¬ìš©: Model.query.filter(Model.id == user_input).first()",
            "ì…ë ¥ ê²€ì¦ ì¶”ê°€: validate_input(user_input) before query"
        ],
        "example": """
# âŒ Vulnerable (DO NOT USE)
def get_user_by_id(user_id):
    query = f"SELECT * FROM users WHERE id = {user_id}"
    cursor.execute(query)

# âœ… Secure (RECOMMENDED)
def get_user_by_id(user_id):
    # Method 1: Parameterized query
    query = "SELECT * FROM users WHERE id = ?"
    cursor.execute(query, (user_id,))

    # Method 2: ORM
    user = User.query.filter(User.id == user_id).first()

    # Method 3: Input validation + parameterized query
    if not isinstance(user_id, int):
        raise ValueError("Invalid user ID")
    cursor.execute("SELECT * FROM users WHERE id = ?", (user_id,))
""",
        "testing_code": """
def test_sql_injection_prevention():
    # Test malicious input
    malicious_input = "1; DROP TABLE users; --"
    try:
        result = get_user_by_id(malicious_input)
        # Should handle safely (no execution of DROP)
        assert result is None or isinstance(result, dict)
    except ValueError:
        pass  # Expected behavior
""",
        "dependencies": ["sqlite3", "sqlalchemy"],
        "cwe": "CWE-89",
        "owasp": "A03:2021 â€“ Injection"
    },

    "XSS": {
        "name": "Cross-Site Scripting (XSS)",
        "description": "ì‚¬ìš©ì ì…ë ¥ì´ HTMLì— ì§ì ‘ ì‚½ì…ë˜ì–´ ì•…ì˜ì ì¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê°€ëŠ¥",
        "principle": "ëª¨ë“  ì‚¬ìš©ì ì…ë ¥ì„ HTML ì´ìŠ¤ì¼€ì´í”„í•˜ê±°ë‚˜ í…œí”Œë¦¿ ì—”ì§„ ì‚¬ìš©",
        "vulnerable_patterns": [
            "f-stringìœ¼ë¡œ HTML ì§ì ‘ ë°˜í™˜: return f\"<div>{user_input}</div>\"",
            "ë¬¸ìì—´ ì—°ê²°ë¡œ HTML êµ¬ì„±: \"<h1>\" + title + \"</h1>\""
        ],
        "secure_patterns": [
            "HTML escape ì‚¬ìš©: escape(user_input)",
            "í…œí”Œë¦¿ ì—”ì§„ ì‚¬ìš©: render_template('page.html', data=user_input)",
            "CSP í—¤ë” ì¶”ê°€: Content-Security-Policy"
        ],
        "example": """
# âŒ Vulnerable
@app.route('/comment', methods=['POST'])
def add_comment():
    comment = request.form['comment']
    return f"<div>{comment}</div>"  # XSS ì·¨ì•½!

# âœ… Secure
from markupsafe import escape
from flask import render_template

@app.route('/comment', methods=['POST'])
def add_comment():
    comment = request.form['comment']

    # Method 1: Manual escape
    safe_comment = escape(comment)
    return f"<div>{safe_comment}</div>"

    # Method 2: Template engine (auto-escape)
    return render_template('comment.html', comment=comment)

# Add CSP header
@app.after_request
def add_security_headers(response):
    response.headers['Content-Security-Policy'] = "default-src 'self'; script-src 'self'"
    return response
""",
        "testing_code": """
def test_xss_prevention():
    from markupsafe import escape
    malicious_input = "<script>alert('XSS')</script>"
    safe_output = escape(malicious_input)
    assert "<script>" not in safe_output
    assert "&lt;script&gt;" in safe_output
""",
        "dependencies": ["markupsafe", "flask"],
        "cwe": "CWE-79",
        "owasp": "A03:2021 â€“ Injection"
    },

    "COMMAND_INJECTION": {
        "name": "Command Injection",
        "description": "ì‚¬ìš©ì ì…ë ¥ì´ ì‹œìŠ¤í…œ ëª…ë ¹ì— ì§ì ‘ ì „ë‹¬ë˜ì–´ ì„ì˜ ëª…ë ¹ ì‹¤í–‰ ê°€ëŠ¥",
        "principle": "shell=False ì‚¬ìš©, ì…ë ¥ ê²€ì¦, í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš©",
        "vulnerable_patterns": [
            "shell=True ì‚¬ìš©: subprocess.run(f'ping {host}', shell=True)",
            "os.system() ì‚¬ìš©: os.system(f'ls {path}')"
        ],
        "secure_patterns": [
            "shell=False + ë¦¬ìŠ¤íŠ¸: subprocess.run(['ping', '-c', '1', host], shell=False)",
            "ì…ë ¥ ê²€ì¦: re.match(r'^[a-zA-Z0-9.-]+$', host)",
            "í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸: if command in ALLOWED_COMMANDS"
        ],
        "example": """
# âŒ Vulnerable
def ping_host(host):
    result = subprocess.run(f"ping -c 1 {host}", shell=True, capture_output=True)
    return result.stdout

# âœ… Secure
import subprocess
import re

ALLOWED_HOSTS_PATTERN = r'^[a-zA-Z0-9.-]+$'

def ping_host(host):
    # Input validation
    if not re.match(ALLOWED_HOSTS_PATTERN, host):
        raise ValueError("Invalid hostname format")

    # shell=False with list arguments
    try:
        result = subprocess.run(
            ['ping', '-c', '1', host],
            capture_output=True,
            text=True,
            timeout=5,
            check=False
        )
        return result.stdout
    except subprocess.TimeoutExpired:
        return "Timeout"
""",
        "testing_code": """
def test_command_injection_prevention():
    malicious_input = "localhost; cat /etc/passwd"
    try:
        result = ping_host(malicious_input)
        assert "/etc/passwd" not in result
    except ValueError:
        pass  # Expected
""",
        "dependencies": ["subprocess", "re"],
        "cwe": "CWE-78",
        "owasp": "A03:2021 â€“ Injection"
    },

    "HARDCODED_SECRET": {
        "name": "Hardcoded Secret",
        "description": "ì½”ë“œì— ì§ì ‘ í•˜ë“œì½”ë”©ëœ ë¹„ë°€ ì •ë³´ (íŒ¨ìŠ¤ì›Œë“œ, API í‚¤ ë“±)",
        "principle": "í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Secret Manager ì‚¬ìš©",
        "vulnerable_patterns": [
            "ì½”ë“œ ë‚´ ì§ì ‘ í• ë‹¹: SECRET_KEY = 'mysecretkey123'",
            "ì„¤ì • íŒŒì¼ì— í‰ë¬¸: api_key: 'sk-abc123'"
        ],
        "secure_patterns": [
            "í™˜ê²½ ë³€ìˆ˜: SECRET_KEY = os.environ.get('SECRET_KEY')",
            ".env íŒŒì¼ + .gitignore: load_dotenv()",
            "Secret Manager: secret = secrets_client.get('SECRET_KEY')"
        ],
        "example": """
# âŒ Vulnerable
SECRET_KEY = 'hardcoded-secret-123'
API_KEY = 'sk-1234567890abcdef'

# âœ… Secure
import os
from dotenv import load_dotenv

load_dotenv()  # Load from .env file

SECRET_KEY = os.environ.get('SECRET_KEY')
if not SECRET_KEY:
    raise ValueError("SECRET_KEY environment variable not set")

API_KEY = os.environ.get('API_KEY')
if not API_KEY:
    raise ValueError("API_KEY environment variable not set")

# For development only
if os.environ.get('ENV') == 'development':
    SECRET_KEY = SECRET_KEY or 'dev-secret-only'
""",
        "env_template": """
# .env (add to .gitignore!)
SECRET_KEY=your-secret-key-here
API_KEY=your-api-key-here
DATABASE_URL=postgresql://user:pass@localhost/db
""",
        "testing_code": """
def test_no_hardcoded_secrets():
    import re
    with open('config.py', 'r') as f:
        content = f.read()
    # Check for hardcoded patterns
    assert not re.search(r'SECRET_KEY\\s*=\\s*["\']\\w+["\']', content)
""",
        "dependencies": ["python-dotenv"],
        "cwe": "CWE-798",
        "owasp": "A07:2021 â€“ Identification and Authentication Failures"
    },

    "UNSAFE_DESERIALIZATION": {
        "name": "Unsafe Deserialization",
        "description": "pickle, yaml.load() ë“± ì•ˆì „í•˜ì§€ ì•Šì€ ì—­ì§ë ¬í™”ë¡œ RCE ê°€ëŠ¥",
        "principle": "JSON ì‚¬ìš© ë˜ëŠ” yaml.safe_load() ì‚¬ìš©",
        "vulnerable_patterns": [
            "pickle.loads(data)",
            "yaml.load(data, Loader=yaml.Loader)"
        ],
        "secure_patterns": [
            "json.loads(data)",
            "yaml.safe_load(data)",
            "Schema validation"
        ],
        "example": """
# âŒ Vulnerable
import pickle
import yaml

def load_data(data):
    obj = pickle.loads(data)  # RCE ê°€ëŠ¥!
    return obj

def load_config(config_str):
    config = yaml.load(config_str, Loader=yaml.Loader)  # RCE ê°€ëŠ¥!
    return config

# âœ… Secure
import json
import yaml

def load_data(data):
    # Use JSON instead
    obj = json.loads(data)
    return obj

def load_config(config_str):
    # Use safe_load
    config = yaml.safe_load(config_str)
    return config

# Add schema validation
from marshmallow import Schema, fields, ValidationError

class UserSchema(Schema):
    name = fields.Str(required=True)
    email = fields.Email(required=True)

def validate_user_data(data):
    schema = UserSchema()
    try:
        validated = schema.load(data)
        return validated
    except ValidationError as e:
        raise ValueError(f"Invalid data: {e.messages}")
""",
        "testing_code": """
def test_safe_deserialization():
    safe_data = '{"name": "test", "value": 123}'
    result = json.loads(safe_data)
    assert result['name'] == 'test'
""",
        "dependencies": ["pyyaml", "marshmallow"],
        "cwe": "CWE-502",
        "owasp": "A08:2021 â€“ Software and Data Integrity Failures"
    }
}


# ============================================================================
# Pydantic Models (Structured Output)
# ============================================================================

class CodeFix(BaseModel):
    """ìˆ˜ì •ëœ ì½”ë“œ ì •ë³´"""
    original_code: str = Field(description="ì›ë³¸ ì·¨ì•½ ì½”ë“œ")
    fixed_code: str = Field(description="ìˆ˜ì •ëœ ì•ˆì „í•œ ì½”ë“œ (ì›ë³¸ì˜ ë³€ìˆ˜ëª…/ë¡œì§ ìœ ì§€)")
    explanation: str = Field(description="ìˆ˜ì • ì‚¬í•­ ì„¤ëª… (í•œê¸€)")
    changes_summary: str = Field(description="ì£¼ìš” ë³€ê²½ì‚¬í•­ ìš”ì•½")
    preserved_elements: List[str] = Field(description="ë³´ì¡´ëœ ìš”ì†Œë“¤ (ë³€ìˆ˜ëª…, í…Œì´ë¸”ëª…, ë¡œì§ ë“±)")


class SecurityFix(BaseModel):
    """ì „ì²´ ë³´ì•ˆ ìˆ˜ì • ì •ë³´"""
    vulnerability_type: str = Field(description="ì·¨ì•½ì  ìœ í˜•")
    file_path: str = Field(description="íŒŒì¼ ê²½ë¡œ")
    line_number: Optional[int] = Field(description="ë¼ì¸ ë²ˆí˜¸")
    severity: str = Field(description="ì‹¬ê°ë„")
    code_fix: CodeFix = Field(description="ì½”ë“œ ìˆ˜ì • ì •ë³´")
    test_code: str = Field(description="ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ì½”ë“œ")
    dependencies: List[str] = Field(description="í•„ìš”í•œ ì˜ì¡´ì„± íŒ¨í‚¤ì§€")
    additional_steps: List[str] = Field(description="ì¶”ê°€ í•„ìš” ì‘ì—…")


# ============================================================================
# Generate Fix Code Tool (LLM-based)
# ============================================================================

class GenerateFixCodeInput(BaseModel):
    """Input schema for generate_fix_code tool"""
    vulnerability: Dict[str, Any] = Field(
        description="""ì·¨ì•½ì  ì •ë³´ (EXACT format required!)

        Required fields:
        - type: str (MUST be EXACT: SQL_INJECTION, XSS, COMMAND_INJECTION, etc.)
        - code: str (actual vulnerable code)
        - file: str (file path)
        - severity: str (optional: CRITICAL, HIGH, MEDIUM, LOW)

        Example:
        {
            "type": "SQL_INJECTION",  # NOT "SQL Injection"!
            "code": "query = f'SELECT * FROM users WHERE id = {user_id}'",
            "file": "app.py:57",
            "severity": "CRITICAL"
        }
        """
    )


class GenerateFixCodeToolV2(BaseTool):
    """LLM ê¸°ë°˜ ì·¨ì•½ì  ìˆ˜ì • ì½”ë“œ ìƒì„± ë„êµ¬ (V2)"""

    name: str = "generate_fix_code"
    description: str = """
    ì·¨ì•½ì ì— ëŒ€í•œ ìˆ˜ì • ì½”ë“œë¥¼ LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
    Templateì€ ë³´ì•ˆ ì›ì¹™ ê°€ì´ë“œë¡œë§Œ ì‚¬ìš©í•˜ê³ , ì‹¤ì œ ì½”ë“œì˜ ë³€ìˆ˜ëª…/ë¡œì§ì„ ìœ ì§€í•˜ë©´ì„œ ì·¨ì•½ì ë§Œ ìˆ˜ì •í•©ë‹ˆë‹¤.

    IMPORTANT - Vulnerability Type Format (EXACT format required):
    - SQL_INJECTION (NOT "SQL Injection")
    - XSS (NOT "Cross-Site Scripting")
    - COMMAND_INJECTION (NOT "Command Injection")
    - HARDCODED_SECRET
    - UNSAFE_DESERIALIZATION
    - PATH_TRAVERSAL
    - SSRF
    - XXE
    - DEBUG_MODE

    Example input:
    {
        "type": "SQL_INJECTION",  # EXACT format!
        "code": "query = f'SELECT * FROM users WHERE id = {user_id}'",
        "file": "app.py:57",
        "severity": "CRITICAL"
    }
    """
    args_schema: type[BaseModel] = GenerateFixCodeInput

    def _get_llm(self):
        """LLM ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (lazy loading)"""
        if not hasattr(self, '_llm'):
            from src.utils.model_selector import get_model_selector, TaskComplexity

            selector = get_model_selector()
            # Don't pass callbacks - LiteLLM global callbacks will handle it
            self._llm = selector.get_llm(TaskComplexity.SECURITY_DESIGN)
            self._parser = JsonOutputParser(pydantic_object=SecurityFix)

        return self._llm

    @property
    def llm(self):
        """LLM property"""
        return self._get_llm()

    @property
    def parser(self):
        """Parser property"""
        self._get_llm()  # Ensure parser is initialized
        return self._parser

    def _run(self, vulnerability: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì·¨ì•½ì  ì •ë³´ë¥¼ ë°›ì•„ LLMì´ ì‹¤ì œ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ìˆ˜ì •

        Args:
            vulnerability: {
                "type": "SQL_INJECTION",  # â† EXACT format (no normalization!)
                "file": "app.py",
                "code": "query = f'SELECT * FROM products WHERE id = {product_id}'",
                "line": 57,
                "severity": "CRITICAL"
            }

        Returns:
            SecurityFix í˜•ì‹ì˜ ìˆ˜ì • ì •ë³´
        """
        try:
            # ì…ë ¥ ê²€ì¦ (ì •ê·œí™” ì—†ìŒ - Agentê°€ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•´ì•¼ í•¨)
            vuln_type = vulnerability.get('type', 'UNKNOWN')
            original_code = vulnerability.get('code', vulnerability.get('description', ''))
            file_path = vulnerability.get('file', 'unknown')
            line_number = vulnerability.get('line')
            severity = vulnerability.get('severity', 'MEDIUM')

            # ë³´ì•ˆ íŒ¨í„´ ê°€ì ¸ì˜¤ê¸°
            pattern = SECURITY_PATTERNS.get(vuln_type)

            if not pattern:
                # ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ (ì •ê·œí™” ì—†ìŒ)
                supported_types = list(SECURITY_PATTERNS.keys())
                return {
                    "error": f"âŒ Unsupported vulnerability type: '{vuln_type}'",
                    "hint": "âš ï¸ You MUST use EXACT format (case-sensitive)",
                    "your_input": vuln_type,
                    "supported_types": supported_types,
                    "examples": {
                        "correct": "SQL_INJECTION",
                        "wrong": ["SQL Injection", "sql injection", "SQLInjection"]
                    },
                    "fix": f"Change '{vuln_type}' to one of: {', '.join(supported_types[:3])}...",
                    "recommendation": "Check agent prompt - vulnerability type format is wrong!"
                }

            if not original_code or original_code.strip() == '':
                return {
                    "error": "ì›ë³¸ ì½”ë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                    "pattern": pattern,
                    "recommendation": "ì·¨ì•½ì  ì •ë³´ì— ì‹¤ì œ ì½”ë“œë¥¼ í¬í•¨ì‹œì¼œì£¼ì„¸ìš”"
                }

            # LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_fix_prompt(
                vuln_type=vuln_type,
                original_code=original_code,
                file_path=file_path,
                line_number=line_number,
                severity=severity,
                pattern=pattern
            )

            # LLM í˜¸ì¶œ (Structured Output)
            response = self.llm.invoke(prompt)

            # JSON íŒŒì‹±
            try:
                # LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
                response_text = response.content if hasattr(response, 'content') else str(response)

                # JSON ë¸”ë¡ ì°¾ê¸° (```json ... ``` ë˜ëŠ” ìˆœìˆ˜ JSON)
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # ìˆœìˆ˜ JSONì¸ ê²½ìš°
                    json_str = response_text

                result = json.loads(json_str)

                # SecurityFix ê²€ì¦
                security_fix = SecurityFix(**result)

                return {
                    "success": True,
                    "vulnerability_type": security_fix.vulnerability_type,
                    "file_path": security_fix.file_path,
                    "line_number": security_fix.line_number,
                    "severity": security_fix.severity,
                    "original_code": security_fix.code_fix.original_code,
                    "fixed_code": security_fix.code_fix.fixed_code,
                    "explanation": security_fix.code_fix.explanation,
                    "changes_summary": security_fix.code_fix.changes_summary,
                    "preserved_elements": security_fix.code_fix.preserved_elements,
                    "test_code": security_fix.test_code,
                    "dependencies": security_fix.dependencies,
                    "additional_steps": security_fix.additional_steps,
                    "cwe": pattern.get("cwe", ""),
                    "owasp": pattern.get("owasp", ""),
                    "generation_method": "LLM with security pattern guidance",
                    "timestamp": time.time()
                }

            except json.JSONDecodeError as e:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
                return {
                    "success": False,
                    "error": f"LLM ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}",
                    "raw_response": response_text[:500],  # ì²˜ìŒ 500ìë§Œ
                    "fallback": self._generate_fallback_fix(vulnerability, pattern)
                }

        except Exception as e:
            return {
                "success": False,
                "error": f"ìˆ˜ì • ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "vulnerability": vulnerability
            }

    def _build_fix_prompt(
        self,
        vuln_type: str,
        original_code: str,
        file_path: str,
        line_number: Optional[int],
        severity: str,
        pattern: Dict[str, Any]
    ) -> str:
        """LLMì„ ìœ„í•œ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        prompt = f"""ë‹¹ì‹ ì€ ë³´ì•ˆ ì „ë¬¸ ê°œë°œìì…ë‹ˆë‹¤. ì•„ë˜ ì·¨ì•½í•œ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ì•ˆì „í•˜ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.

## ì·¨ì•½ì  ì •ë³´
- **ìœ í˜•**: {pattern['name']} ({vuln_type})
- **íŒŒì¼**: {file_path}
{f"- **ë¼ì¸**: {line_number}" if line_number else ""}
- **ì‹¬ê°ë„**: {severity}
- **CWE**: {pattern.get('cwe', 'N/A')}
- **OWASP**: {pattern.get('owasp', 'N/A')}

## ì›ë³¸ ì·¨ì•½ ì½”ë“œ
```python
{original_code}
```

## ë³´ì•ˆ ì›ì¹™
{pattern['description']}

**ìˆ˜ì • ì›ì¹™**: {pattern['principle']}

## ì·¨ì•½í•œ íŒ¨í„´ë“¤
{chr(10).join(f'- {p}' for p in pattern['vulnerable_patterns'])}

## ì•ˆì „í•œ íŒ¨í„´ë“¤
{chr(10).join(f'- {p}' for p in pattern['secure_patterns'])}

## ì°¸ê³  ì˜ˆì‹œ
{pattern['example']}

## ìˆ˜ì • ìš”êµ¬ì‚¬í•­
1. **ì›ë³¸ ì½”ë“œì˜ êµ¬ì¡°ë¥¼ ìµœëŒ€í•œ ë³´ì¡´**í•˜ì„¸ìš” (ë³€ìˆ˜ëª…, í…Œì´ë¸”ëª…, í•¨ìˆ˜ëª…, ë¡œì§ íë¦„ ìœ ì§€)
2. **ì·¨ì•½ì ë§Œ ì œê±°**í•˜ì„¸ìš” (ë¶ˆí•„ìš”í•œ ë¦¬íŒ©í† ë§ ê¸ˆì§€)
3. **ì‹¤ì œ ë™ì‘í•˜ëŠ” ì™„ì „í•œ ì½”ë“œ**ë¥¼ ì‘ì„±í•˜ì„¸ìš” (import, í•¨ìˆ˜ ì •ì˜ í¬í•¨)
4. **Python 3.10+ ë¬¸ë²•**ì„ ì‚¬ìš©í•˜ì„¸ìš”
5. **ì£¼ì„ì„ ì¶”ê°€**í•˜ì—¬ ìˆ˜ì • ì‚¬í•­ì„ ëª…í™•íˆ í•˜ì„¸ìš”

## ì¶œë ¥ í˜•ì‹ (JSON)
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

```json
{{
  "vulnerability_type": "{vuln_type}",
  "file_path": "{file_path}",
  "line_number": {line_number or 'null'},
  "severity": "{severity}",
  "code_fix": {{
    "original_code": "ì›ë³¸ ì½”ë“œ (ê·¸ëŒ€ë¡œ)",
    "fixed_code": "ìˆ˜ì •ëœ ì½”ë“œ (ì™„ì „í•œ í•¨ìˆ˜/í´ë˜ìŠ¤)",
    "explanation": "ìˆ˜ì • ì‚¬í•­ ìƒì„¸ ì„¤ëª… (í•œê¸€, 200ì ì´ë‚´)",
    "changes_summary": "ì£¼ìš” ë³€ê²½ì‚¬í•­ (í•œê¸€, 50ì ì´ë‚´)",
    "preserved_elements": ["ìœ ì§€ëœ ë³€ìˆ˜ëª…", "ìœ ì§€ëœ í…Œì´ë¸”ëª…", "ìœ ì§€ëœ ë¡œì§"]
  }},
  "test_code": "ê²€ì¦ìš© pytest í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì™„ì „í•œ í•¨ìˆ˜)",
  "dependencies": ["{chr(34).join(pattern['dependencies'])}"],
  "additional_steps": ["ì¶”ê°€ í•„ìš” ì‘ì—… 1", "ì¶”ê°€ í•„ìš” ì‘ì—… 2"]
}}
```

**ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
"""

        return prompt

    def _generate_fallback_fix(
        self,
        vulnerability: Dict[str, Any],
        pattern: Dict[str, Any]
    ) -> Dict[str, Any]:
        """LLM ì‹¤íŒ¨ ì‹œ Template ê¸°ë°˜ fallback"""

        vuln_type = vulnerability.get('type', 'UNKNOWN')
        original_code = vulnerability.get('code', '')
        file_path = vulnerability.get('file', 'unknown')

        return {
            "vulnerability_type": vuln_type,
            "file_path": file_path,
            "severity": vulnerability.get('severity', 'MEDIUM'),
            "description": pattern['description'],
            "principle": pattern['principle'],
            "example_fix": pattern['example'],
            "test_code": pattern.get('testing_code', ''),
            "dependencies": pattern.get('dependencies', []),
            "warning": "LLM ìƒì„± ì‹¤íŒ¨ë¡œ Template ê¸°ë°˜ ì˜ˆì‹œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì‹¤ì œ ì½”ë“œì— ë§ê²Œ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            "manual_review_required": True
        }


# ============================================================================
# CrewAI-compatible tool wrapper
# ============================================================================

from crewai.tools import tool

@tool("Generate Fix Code")
def generate_fix_code(vulnerability: Dict[str, Any]) -> dict:
    """
    LLM ê¸°ë°˜ ì·¨ì•½ì  ìˆ˜ì • ì½”ë“œ ìƒì„± (V2)

    Templateì€ ë³´ì•ˆ ì›ì¹™ ê°€ì´ë“œë¡œë§Œ ì‚¬ìš©í•˜ê³ , LLMì´ ì‹¤ì œ ì½”ë“œì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬
    ë³€ìˆ˜ëª…/í…Œì´ë¸”ëª…/ë¡œì§ì„ ìœ ì§€í•˜ë©´ì„œ ì·¨ì•½ì ë§Œ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        vulnerability: {
            "type": "SQL_INJECTION",
            "file": "app.py:57",
            "code": "query = f'SELECT * FROM products WHERE id = {product_id}'",
            "severity": "CRITICAL"
        }

    Returns:
        ìˆ˜ì •ëœ ì½”ë“œ, ì„¤ëª…, í…ŒìŠ¤íŠ¸ ì½”ë“œ, ì˜ì¡´ì„± ë“±ì„ í¬í•¨í•œ ìƒì„¸ ì •ë³´
    """
    tool_instance = GenerateFixCodeToolV2()
    return tool_instance._run(vulnerability=vulnerability)


@tool("Create PR Template")
def create_pr_template(vulnerabilities: Optional[Any] = None, project_info: Optional[Any] = None) -> str:
    """
    GitHub Pull Request í…œí”Œë¦¿ ìƒì„±

    ì·¨ì•½ì  ëª©ë¡ê³¼ ìˆ˜ì • ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë³´ì•ˆ íŒ¨ì¹˜ PR ë¬¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

    Args:
        vulnerabilities: ì·¨ì•½ì  ëª©ë¡ (list of dicts)
        project_info: í”„ë¡œì íŠ¸ ì •ë³´ (dict)

    Returns:
        Markdown í˜•ì‹ì˜ PR í…œí”Œë¦¿
    """
    try:
        if not vulnerabilities:
            vulnerabilities = []

        pr_sections = [
            "# ğŸ”’ Security Fix Pull Request",
            "",
            "## ğŸ“‹ Summary",
            f"This PR fixes **{len(vulnerabilities)} security vulnerabilities** identified during automated security analysis.",
            "",
            "## ğŸ› Vulnerabilities Fixed",
            ""
        ]

        # ì·¨ì•½ì  ëª©ë¡
        for idx, vuln in enumerate(vulnerabilities, 1):
            severity = vuln.get('severity', 'UNKNOWN')
            vuln_type = vuln.get('type', 'Unknown')
            file_path = vuln.get('file', 'unknown')

            pr_sections.extend([
                f"### {idx}. {vuln_type} ({severity})",
                f"- **File**: `{file_path}`",
                f"- **Description**: {vuln.get('description', 'Security vulnerability detected')}",
                ""
            ])

        # í…ŒìŠ¤íŠ¸ ê³„íš
        pr_sections.extend([
            "## âœ… Testing",
            "- [ ] Unit tests pass",
            "- [ ] Security tests pass",
            "- [ ] Manual testing completed",
            "",
            "## ğŸ“š References",
            "- [OWASP Top 10](https://owasp.org/www-project-top-ten/)",
            "- [CWE Database](https://cwe.mitre.org/)",
            "",
            "## ğŸ¤– Generated by Security Agent Portfolio",
            ""
        ])

        return '\n'.join(pr_sections)

    except Exception as e:
        logger.error(f"Error creating PR template: {e}")
        return f"# Security Fix PR\n\nError generating template: {str(e)}"


@tool("Generate Security Documentation")
def generate_security_documentation(vulnerabilities: Optional[Any] = None, fixes: Optional[Any] = None) -> dict:
    """
    ë³´ì•ˆ ë¬¸ì„œ ìƒì„±

    SECURITY.md, README ë³´ì•ˆ ì„¹ì…˜ ë“± í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ë³´ì•ˆ ë¬¸ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

    Args:
        vulnerabilities: ì·¨ì•½ì  ëª©ë¡
        fixes: ìˆ˜ì • ì‚¬í•­ ëª©ë¡

    Returns:
        ë¬¸ì„œ íƒ€ì…ë³„ ë‚´ìš©ì„ ë‹´ì€ dict
    """
    try:
        security_md = [
            "# Security Policy",
            "",
            "## Supported Versions",
            "| Version | Supported |",
            "|---------|-----------|",
            "| Latest  | âœ…        |",
            "",
            "## Reporting a Vulnerability",
            "Please report security vulnerabilities to security@example.com",
            "",
            "## Recent Security Fixes",
            ""
        ]

        if vulnerabilities:
            for vuln in vulnerabilities:
                vuln_type = vuln.get('type', 'Unknown')
                severity = vuln.get('severity', 'UNKNOWN')
                security_md.append(f"- Fixed {vuln_type} ({severity})")

        return {
            "security_md": '\n'.join(security_md),
            "readme_section": "## ğŸ”’ Security\n\nThis project follows security best practices. See [SECURITY.md](SECURITY.md) for details.",
            "env_example": "# Security Configuration\nSECRET_KEY=your-secret-key-here\nAPI_KEY=your-api-key-here\n"
        }

    except Exception as e:
        logger.error(f"Error generating security docs: {e}")
        return {"error": str(e)}


@tool("Generate Fix Script")
def generate_fix_script(vulnerabilities: Optional[Any] = None) -> str:
    """
    ì·¨ì•½ì  ìˆ˜ì • ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±

    í™˜ê²½ ì„¤ì •, ì˜ì¡´ì„± ì—…ë°ì´íŠ¸, ë³´ì•ˆ ê²€ì¦ ë“±ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” Bash ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

    Args:
        vulnerabilities: ì·¨ì•½ì  ëª©ë¡

    Returns:
        Bash ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©
    """
    try:
        script_lines = [
            "#!/bin/bash",
            "set -e",
            "",
            "echo 'ğŸ”’ Security Fix Automation Script'",
            "echo '=================================='",
            "",
            "# Update dependencies",
            "echo 'Updating dependencies...'",
            "pip install --upgrade pip",
            "",
            "# Install security tools",
            "echo 'Installing security tools...'",
            "pip install bandit safety",
            "",
            "# Run security checks",
            "echo 'Running security checks...'",
            "bandit -r . -x tests/ || echo 'Security issues found'",
            "safety check || echo 'Dependency vulnerabilities found'",
            "",
            "echo 'âœ… Security fixes completed!'",
            ""
        ]

        return '\n'.join(script_lines)

    except Exception as e:
        logger.error(f"Error generating fix script: {e}")
        return f"#!/bin/bash\necho 'Error: {str(e)}'\n"


# Tool instance export (lazy initialization)
def get_tool_instance():
    """Lazy initialization of tool instance"""
    return GenerateFixCodeToolV2()

__all__ = [
    'GenerateFixCodeToolV2',
    'generate_fix_code',
    'create_pr_template',
    'generate_security_documentation',
    'generate_fix_script',
    'SECURITY_PATTERNS',
    'SecurityFix',
    'CodeFix',
    'get_tool_instance'
]